# Task Intern at Career

---------------------------------------------------------------------------------------------------------------------------------

Welcome to the **Task Intern Career** repository! This folder contains the tasks assigned to me during the internship program to enhance my Python development skills. Below is a description of the two main tasks and their corresponding folders.

---------------------------------------------------------------------------------------------------------------------------------

## Overview

This repository is organized into two main tasks:

- **Task 1: Web Scraping and Automation**
- **Task 2: Data Processing Automation**

Each task has its own dedicated folder containing the relevant scripts, documentation, and any associated files.

---------------------------------------------------------------------------------------------------------------------------------

## Folder Structure

### `web_scraping`

This folder contains the materials for Task 1, which focuses on web scraping and automation.

---------------------------------------------------------------------------------------------------------------------------------

#### Key Components:
- **Scripts:** Python scripts that utilize libraries such as BeautifulSoup and Requests to scrape data from publicly accessible websites.
- **Documentation:** A document explaining the purpose of the scripts, how to run them, and any dependencies required.
- **Additional Files:** Any additional files or resources used in the web scraping task.

#### Task 1 Objectives:
1. **Choose the Right Website:** Select a website with publicly accessible data.
2. **Use Web Scraping Libraries:** Write scripts using BeautifulSoup and Requests for effective web scraping.
3. **Data Processing:** Clean and organize the scraped data using Pandas.
4. **Automation:** Schedule the script for regular updates using tools like Cron or Task Scheduler.
5. **Documentation:** Provide a clear explanation of the script's purpose and usage.

---------------------------------------------------------------------------------------------------------------------------------

### `data_process`

This folder contains the materials for Task 2, which focuses on data processing.

---------------------------------------------------------------------------------------------------------------------------------

#### Key Components:
- **Scripts:** Python scripts designed to read, process, and analyze datasets. This includes tasks like calculating summary statistics, data filtering, generating visualizations, and saving processed data.
- **Documentation:** A brief document explaining the usage of the scripts, their functions, and any dependencies required.
- **Additional Files:** Any additional files or resources related to data processing.

---------------------------------------------------------------------------------------------------------------------------------

#### Task 2 Objectives:
1. **Choose a Dataset:** Select a dataset related to a domain of interest.
2. **Write a Versatile Script:** Develop a script for reading and processing the dataset, performing operations such as calculating statistics and generating visualizations.
3. **Automation:** Ensure the script is versatile and can handle multiple datasets.
4. **Documentation:** Provide a clear explanation of the script's functions and usage.

---------------------------------------------------------------------------------------------------------------------------------

## Unit Testing
This folder contains the unit tests for both Task 1 and Task 2. These tests are essential for verifying the correctness and reliability of the scripts.

### How to Run the Tests
To run all the tests in the repository, execute the following command from the root directory:
`python -m unittest discover` or;
`follow the instructions in each of the code`.

This command will automatically discover and run all test cases in the project.

### Key Components:
* Test Files: Python test files that cover different aspects of the scripts, ensuring they handle various scenarios and edge cases.
* Mocking: Utilizes `unittest.mock` to simulate external dependencies like HTTP requests during testing.
* Test Coverage: The tests cover functions like data extraction, processing, and saving, ensuring all critical components are functioning correctly.

---------------------------------------------------------------------------------------------------------------------------------

## Getting Started

To get started with the tasks:
1. **Clone the Repository:** Clone the repository to your local machine using `git clone "repository-url"`.
2. **Navigate to Folders:** Navigate to the relevant folder (`web_scraping` or `data_process`) to access the scripts and documentation.
3. **Install Dependencies:** Follow the installation instructions provided in each folder's documentation to set up any necessary libraries and tools.

---------------------------------------------------------------------------------------------------------------------------------

## Recommended Tools

- **Code Editors:** Visual Studio Code, PyCharm, or Jupyter Notebooks for an interactive environment.
- **Version Control:** Use Git and GitHub for tracking changes and collaborative work.
- **Libraries:** Leverage libraries like Pandas, NumPy, Matplotlib, and Seaborn for data manipulation and visualization.
- **Virtual Environment:** Set up virtual environments using virtualenv or conda for project isolation.
- **Documentation:** Use tools like Sphinx or MkDocs for creating documentation.

---------------------------------------------------------------------------------------------------------------------------------

For any questions or assistance, please refer to the documentation within each folder or reach out for support at dagwanpan@gmail.com  | dan21017@byui.edu. Enjoy your Python development journey!
